{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_20:0\", shape=(2,), dtype=float32)\n",
      "[3. 5.]\n",
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1.0, 2.0], name='a', dtype=tf.float32)  # 定义常量向量\n",
    "b = tf.constant([2.0, 3.0], name='b')\n",
    "result = a + b  # 向量相加\n",
    "print(result)\n",
    "\n",
    "# 先生成一个会话，通过该会话来计算结果\n",
    "# sess = tf.Session()\n",
    "sess = tf.InteractiveSession()  # 自动将生成的会话注册为默认会话\n",
    "print(sess.run(result))\n",
    "print(result.eval(session=sess))\n",
    "sess.close()  # 关闭会话，释放资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算模型\n",
    "\n",
    "- TensorFlow中的所有计算都会被转化为计算图上的节点。\n",
    "- 而节点之间的边描述了计算之间的依赖关系。\n",
    "- 在TensorFlow中，张量可以被简单地理解为多维数组。\n",
    "- TensorFlow是一个通过计算图的形式来表述计算的编程系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()  # 生成新的计算图\n",
    "with g1.as_default():\n",
    "    # 在计算图g1中定义变量'v'，并设置初始值为0\n",
    "    v = tf.get_variable(\"v\", initializer=tf.zeros(shape=[1]))\n",
    "    \n",
    "# 在计算图g1中读取变量'v'的值\n",
    "with tf.Session(graph=g1) as sess:  # 通过上下文管理器来使用会话\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        print(sess.run(tf.get_variable('v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在张量中，并没有真正保存数字，它保存的是如何得到这些数字的计算过程。\n",
    "- 一个张量中主要保存了三个属性：名字、维度、类型。\n",
    "- 张量的命名可通过\"node:src_output\"的形式给出。其中，node为节点名称，src_output表示当前张量来自节点的第几个输出。\n",
    "- TensorFlow支持的类型主要包括：tf.float32, tf.float64, tf.int8, tf.int16, tf.int32, tf.int64, tf.uint8, tf.bool, tf.complex64, tf.complex128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "sess1 = tf.InteractiveSession(config=config)\n",
    "sess2 = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow及神经网络\n",
    "\n",
    "神经网络解决分类问题的主要步骤：\n",
    "- 提取问题中实体的特征向量作为神经网络的输入。\n",
    "- 定义神经网络的结构，并定义如何从神经网络的输入得到输出。\n",
    "- 通过训练数据来调整神经网络中参数的取值，这就是训练神经网络的过程。\n",
    "- 使用训练好的神经网络来预测未知的数据。\n",
    "\n",
    "全连接神经网络：相邻两层之间任意两个节点之间都有连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow支持的随机数生成函数：\n",
    "- `tf.random_normal`：正态分布。\n",
    "- `tf.truncated_normal`：正态分布，但若随机值偏离平均值超过2个标准差，将被重新随机。\n",
    "- `tf.random_uniform`：平均分布。\n",
    "- `tf.random_gamma`：Gamma分布。\n",
    "\n",
    "TensorFlow常数生成函数：\n",
    "- `tf.zeros([2,3], int32)`：产生全0的数组。\n",
    "- `tf.ones([2,3], int32)`：产生全1的数组。\n",
    "- `tf.fill([2,3], 9)`：产生一个全部为给定数字的组合。\n",
    "- `tf.constant([1,2,3)`：产生一个给定值的常量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 声明一个2*3的矩阵变量，并赋予均值为0，标准差为2的随机数\n",
    "weigths = tf.Variable(tf.random_normal([2, 3], mean=0, stddev=2))\n",
    "biases = tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578]]\n",
      "<function all_variables at 0x000000001B7790D0>\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))  # 该运算的输出结果即为张量\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "x = tf.constant([[0.7, 0.9]])  # 1*2的矩阵\n",
    "\n",
    "a = tf.matmul(x, w1)  # 矩阵乘法\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(w1.initializer)  # 逐个初始化变量\n",
    "    # sess.run(w2.initializer)\n",
    "    # 初始化所有变量\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y))\n",
    "    print(tf.all_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.all_variables`：可拿到当前计算图上所有的变量。\n",
    "- `tf.trainable_variables`：得到所有需要优化的参数。\n",
    "- 变量的类型是不可改变的。\n",
    "- 维度在程序运行中是有可能改变的，需通过设置参数`validate_shape=False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_2:0' shape=(2, 2) dtype=float32_ref>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1)) \n",
    "w2 = tf.Variable(tf.random_normal([2, 2], stddev=1, seed=1))\n",
    "\n",
    "# tf.assign(w1, w2)  # wrong\n",
    "tf.assign(w1, w2, validate_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578 ]\n",
      " [1.1537654]\n",
      " [3.1674924]]\n"
     ]
    }
   ],
   "source": [
    "# 使用placeholder实现前向传播算法\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "# 输入为n*2矩阵，前向传播结果为n*1的矩阵\n",
    "# placeholder中数据的维度信息可以根据提供的数据推导得出，所有不一定要给出\n",
    "x = tf.placeholder(tf.float32, shape=(3, 2), name='input') \n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "# print(sess.run(y))  # 某个需要的placeholder没有被指定取值，报错\n",
    "print(sess.run(y, feed_dict={x: [[0.7, 0.9], [0.1, 0.4], [0.5, 0.8]]}))  # 指定x的取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "[[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "After 0 training step(s), cross entropy on all data is 0.0674925\n",
      "After 1000 training step(s), cross entropy on all data is 0.0163385\n",
      "After 2000 training step(s), cross entropy on all data is 0.00907547\n",
      "After 3000 training step(s), cross entropy on all data is 0.00714436\n",
      "After 4000 training step(s), cross entropy on all data is 0.00578471\n",
      "[[-1.9618274  2.582354   1.6820377]\n",
      " [-3.4681718  1.0698233  2.11789  ]]\n",
      "[[-1.8247149]\n",
      " [ 2.6854665]\n",
      " [ 1.418195 ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "# 定义损失函数和反向传播的算法\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "# 通过随机数生成一个模拟数据集\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "Y = [[int(x1 + x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "# 创建会话\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    \n",
    "    STEPS = 5000  # 训练的轮数\n",
    "    for i in range(STEPS):\n",
    "        # 每次选取batch_size个样本进行训练\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start+batch_size, dataset_size)\n",
    "        # 根据样本训练神经网络并更新参数\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            # 每个一定轮数，计算在所有数据上的交叉熵\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y})\n",
    "            print(\"After %d training step(s), cross entropy on all data is %g\" % (i, total_cross_entropy))\n",
    "            \n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练神经网络的过程：\n",
    "- 定义神经网络的结构和前向传播算法的输出结果；\n",
    "- 定义损失函数以及选择反向传播优化的算法；\n",
    "- 生成会话，并且在训练数据上反复运行反向传播优化算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
